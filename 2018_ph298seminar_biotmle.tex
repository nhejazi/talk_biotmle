\documentclass{beamer}
\usetheme{metropolis}

% specifications for presenter mode
%\beamerdefaultoverlayspecification{<+->}
%\setbeamercovered{transparent}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}

%\usepackage{coloremoji}
\usepackage{layout}
\usepackage{multirow}
\usepackage{array}
\usepackage{graphicx}
\graphicspath{ {Figs/} }

\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}
\usepackage{datetime}
\usepackage{url}
\usepackage{tcolorbox}
\usepackage{appendixnumberbeamer}

% math shorthand
\usepackage{bm}
\usepackage{bbm}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{mathptmx}
\usepackage{dsfont}
\usepackage{psfrag}
\usepackage{epsfig}
\usepackage{float}
\usepackage{breqn}
\newcommand{\R}{\mathbb{R}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\lik}{\mathcal{L}}

\newtheorem*{assumption*}{\assumptionnumber}
\providecommand{\assumptionnumber}{}
\makeatletter
\newenvironment{assumption}[2]
 {%
  \renewcommand{\assumptionnumber}{Assumption #1: $\mathcal{#2}$}%
  \begin{assumption*}%
  \protected@edef\@currentlabel{#1: $\mathcal{#2}$}%
 }
 {%
  \end{assumption*}
 }
\makeatother

\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
  #1\;\delimsize\|\;#2%
}
\newcommand{\infdiv}{D\infdivx}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

% indepndence notation macro
\newcommand\indep{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

% Bibliography
\usepackage{natbib}
\bibpunct{(}{)}{,}{a}{}{;}
\usepackage{bibentry}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% title info
\title{\normalsize Variance Moderation of Locally Efficient Estimators in
  High-Dimensional Biology}

\subtitle{\scriptsize Nonparametric variable importance analysis, multiple
  testing corrections, supervised clustering, and open source software\\[-10pt]}

\author{\href{https://nimahejazi.org}{Nima Hejazi}\\[-10pt]}

\institute{
  \begin{figure}[!htb]
    \centering
    \begin{minipage}{.65\textwidth}
        Group in Biostatistics, and \\
        Center for Computational Biology, \\
        University of California, Berkeley \\[6pt]
        \includegraphics[scale=0.12]{twitter-icon.png}
          \href{https://twitter.com/nshejazi}{nshejazi} \\
        \includegraphics[scale=0.09]{github-icon.png}
          \href{https://github.com/nhejazi}{nhejazi} \\
        \includegraphics[scale=0.12]{homepage.png}
          \href{https://nimahejazi.org}{nimahejazi.org} \\
        \includegraphics[scale=0.12]{pdf-icon.png}
          \href{https://bit.ly/2018\_biostat\_quals}{bit.ly/2018\_biostat\_quals}
    \end{minipage}%
    \begin{minipage}{0.35\textwidth}
      \centering
      \includegraphics[height=0.80in,width=0.80in]{ucberkeleyseal_874_540.eps}
    \end{minipage}
  \end{figure}
}

\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{frame}[noframenumbering]
  \thispagestyle{empty}
  \titlepage
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c,noframenumbering]{Preview}
\thispagestyle{empty}
\begin{center}
\begin{enumerate}
  \itemsep12pt
  \item Linear models are the standard approach for analyzing microarray and
    next-generation sequencing data (e.g., R package ``limma'').
  \item Moderated statistics help reduce false positives by using an empirical
    Bayes method to perform standard deviation shrinkage for test statistics.
  \item \textit{Beyond linear models:} we can assess evidence using parameters
    that are more scientifically interesting (e.g., ATE) by way of TMLE.
  \item The approach of moderated statistics easily extends to the case of
    asymptotically linear parameters.
\end{enumerate}
\end{center}

\note{We'll go over this summary again at the end of the talk. Hopefully, it
      will all make more sense then.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivations and Preliminaries}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Motivation: Let's meet the data}
\begin{center}
\begin{itemize}
  \itemsep12pt
  \item Observational study of the impact of occupational exposure (to benzene),
    with data collected on $125$ subjects and roughly $22,000$ biomarkers.
  \item Biomarkers of interest are in the form of \textbf{miRNA}, assessed
    using the \textit{Illumina Human Ref-8 BeadChips} platform.
  \item Occupational exposure to benzene reported as discrete values of
    interest (to epidemiologists): none, $<1$ppm, $>5$ppm.
  \item Background (phenotype-level) information available on each subject,
    including age, sex, smoking status.
\end{itemize}
\end{center}

\note{This is not an atypical data set by modern standards in epidemiology,
      certainly not the standard for molecular biology. That is, sample sizes
      are usually much smaller in experiments examining biological processes.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Data analysis? Linear models!}
\begin{center}
\begin{itemize}
  \itemsep12pt
  \item For each biomarker ($b = 1, \dots, B$), fit a linear model:
    \[
    \mathbb{E}[y_b] = X \beta_b
    \]
  \item Generally, we have a particular model coefficent in which we are
    interested (e.g., effect of benzene on biomarker expression).
  \item Controlling for baseline covariates, batch effects, and potential
    confounders happens by adding terms to the linear model.
  \item Test the coefficent of interest using a standard t-test:
    \[
      t_{b} = \frac{\hat{\beta}_{b} - \beta_{b, H_0}}{s_b}
    \]
\end{itemize}
\end{center}

\note{There's nothing particularly wrong with this approach. It's exactly what
      we would come up with after a first-year statistics course. In practice,
      there are many issues: (1) we are forced to specify a functional form, the
      linear model; (2) we end up with unstable variance estimates that sharply
      increase the number of false positives detected, even after multiple
      testing corrections.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Robustified Variance Estimation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{LIMMA: Linear Models for Microarray Data}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item When the sample size is small, $s^2_b$ may be so small that small
    differences ($\hat{\beta}_{b} - \beta_{b, H_0}$) lead to large $t_{b}$.
  \item Uncertainty in the variance is an acute problem when the sample size is
    small.
  \item This results in false positives. Smyth proposes we get around this by an
    empirical Bayes shrinkage of the $s^2_b$.
  \item Test the coefficent of interest with a \textbf{moderated} t-test:
    \[
      \tilde{t}_{b} = \frac{\hat{\beta}_{b} - \beta_{b, H_0}}{\tilde{s}_b},
      \;
      \tilde{s}^2_b = \frac{s^2_bd_b + s^2_0d_0}{d_b + d_0}
    \]
  \item Eliminates large t-statistics merely from very small $s_b$.
\end{itemize}
\end{center}

\note{The substantive contribution here is the use of an empirical Bayes method
      to shrink the standard deviation across all of the biomarkers such that we
      obtain a larger (but accurate) estimate that reduces the number of test
      statistics that are marked as significant by low $s^2_b$ estimates alone.

      Note that this is \textbf{not} the exact formulation of the moderated
      t-statistic as given by Smyth (his derivation assumes a hierarchical
      model; see original paper if interested). This formulation does a good
      enough job to help us see the bigger picture.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Beyond linear models}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item It's not always desirable to specify a functional form: perhaps we can
    do better than linear models?
  \item Such models are a matter of convenience and not honest scientific
    practice: does $\hat{\beta}_{b}$ really answer our questions?
  \item We can do better by using parameters motivated by causal models (n.b.,
    these will reduce to ``variable importance measures'' in our case).
  \item As long as the parameters we seek to estimate have asymptotically linear
    estimators, we can readily apply the approach of moderated statistics.
\end{itemize}
\end{center}

\note{Linear models are convenient for communicating results --- that is, all
      scientists are trained to understand them. This means they provide a basic
      way of easily communicating between statisticians and collaborators. That
      said, doesn't it seem a bit odd to use such elementary models to analyze
      complex biological sequencing data? We're using old statistical technology
      to analyze classes of data that have only recently become available.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{A Role for Targeted Learning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Target parameters for complex questions}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item Rather than being satisfied with $\hat{\beta}_{b}$ as an answer to our
    questions, let's consider a simple target parameter: the average treatment
    effect (ATE):
    \[
      \Psi_b(P_0) = \mathbb{E}_{W,0}[\mathbb{E}_0[Y_b \mid A = a_{high}, W] -
      \mathbb{E}_0[Y_b \mid A = a_{low}, W]]
    \]
  \item No need to specify a functional form or assume that we know the true
    data-generating distribution $P_0$.
  \item Parameters like this can be estimated using \textit{targeted minimum
    loss-based estimation} (TMLE).
  \item \textbf{Asymptotic linearity:}
    \[
      \Psi_b(P_n^*) - \Psi_b(P_0) = \frac{1}{n} \sum_{i = 1}^{n} IC(O_i) +
      o_P(\frac{1}{\sqrt{n}})
    \]
\end{itemize}
\end{center}

\note{By allowing scientific questions to inform the parameters that we choose
      to estimate, we can do a better job of actually answering the questions of
      interest to our collaborators. Further, we abandon the need to specify the
      functional relationship between our outcome and covariates; moreover, we
      can now make use of advances in machine learning.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Targeted Minimum Loss-Based Estimation}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item TMLE produces a well-defined, unbiased, efficient substitution estimator
    of target parameters of a data-generating distribution.
  \item Iterative procedure (though there is a one-step now) that updates an
    initial estimate of the relevant part ($Q_0$) of the data generating
    distribution ($P_0$).
  \item Like corresponding A-IPTW estimators, removes asymptotic residual bias
    of initial estimator for the target parameter. If it uses a consistent
    estimator of $g_0$ (nuisance parameter), it is \textit{doubly robust}.
  \item We can estimate the target parameter:
    \[
      \Psi_b(P_n^*) = \frac{1}{n}\sum_{i=1}^{n}[Q_n^{(b,1)}(A_i = a_h, W_i) -
      Q_n^{(b,1)}(A_i = a_l, W_i)]
    \]
\end{itemize}
\end{center}

\note{Natural use of machine learning methods for the estimation of both $Q_0$
      and $g_0$. Focuses effort to achieve minimal bias and asymptotic
      semiparametric efficiency bound for the variance, but still get inference
      (with some assumptions).
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Robust Inference and Influence Functions}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Inference with influence curves}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item The influence curve for the estimator is:
  \begin{dmath}
    IC_{b,n}(O_i) = \left (\frac{\mathbbm{1}(A_i = a_{h})}{g_n(a_{h} \mid W_i)}
    - \frac{\mathbbm{1}(A_i = a_{l})}{g_n (a_{l} \mid W_i)} \right) \cdot
    (Y_{b,i} - \bar{Q}^{(b,1)}_n(A_i, W_i)) +
    \bar{Q}^{(b,1)}_n(a_{h}, W_i) - \bar{Q}^{(b,1)}_n(a_{l}, W_i) -
    \Psi_{b}(P_n^*)
  \end{dmath}
  \item Sample variance of the influence curve:
    \[
      \textstyle s^2(IC_n) = \frac{1}{n}\sum_{i=1}^n\left(IC_n(O_i) \right)^2
    \]
  \item Use sample variance to estimate the standard error:
    \[
      se_n = \sqrt{\frac{s^2(IC_n)}{n}}
    \]
  \item Use this for inference --- that is, to derive uncertainty measures
    (i.e., p-values, confidence intervals).
\end{itemize}
\end{center}

\note{Using the influence curve representation, we can obtain all of the
  standard objects of statistical interest, but for more interesting parameters.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Moderated statistics for target parameters}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item One can define a standard t-test statistic for an estimator of an
    asymptotically linear parameter (over $b = 1, \dots, B$) as:
    \[
      t_b = \frac{\sqrt{n}(\Psi_b(P_n^*) - \Psi_0)}{s_b(IC_{b,n})}
    \]
  \item This naturally extends to the moderated t-statistic of Smyth:
    \[
      \tilde{t}_b = \frac{\sqrt{n}(\Psi_b(P_n^*) - \Psi_0)}{\tilde{s}_b}
    \]
    where the posterior estimate of the variance of the influence curve is
    \[
      \tilde{s}^2_b = \frac{s^2_b(IC_{b,n})d_b + s^2_0d_0}{d_b + d_0}
    \]
\end{itemize}
\end{center}

\note{
  \begin{itemize}
    \item Consider this is repeated for $b = 1, \ldots, B$  different
      biomarkers, so that one has, for each $b$:
      $$\Psi_b(Q_{b,n}^{*}), S_b^2(IC_{b,n}),$$
      estimate of variable importance and standard error for all $B$.
    \item Propose an existing joint-inferential procedure that can add some
      finite-sample robustness to an estimator that can be highly variable.
   \end{itemize}
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{An influence curve transform}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item Need the estimate for each biomarker ($b$) and the IC for every
    observation for that biomarker, repeating for all $b = 1, \dots, B$.
  \item Essentially, transform original data matrix such that new entries are:
    \[
      Y^*_{b,i} = IC_{b,n}(O_i; P_n) + \Psi_b(P_n^*)
     \]
 \item Since $\mathbb{E}[IC_{b,n}] = 0$ across the columns (units) for each $b$,
   the average will be the original estimate $\Psi_b(P_n^*)$.
  \item For simplicity, let's assume the null value is $\Psi_0 = 0$ for all $b$.
    Then, applying the moderated t-test to $Y^*_{b,i}$ will generate corrected,
    conservative test statistics $\tilde{t}_b$.
\end{itemize}
\end{center}

\note{Just like the one-sample problem for estimation of parameter with
    associated standard error from the influence curve.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Why moderated statistics in this context?}

\begin{center}
\begin{itemize}
  \item Often times, such data analyses are based on relatively small samples.
  \item To get a data-adaptive estimate, with standard implementation of these
    estimates, standard errors can be non-robust.
\item Practically, ``significant'' estimates of variable importance measures may
  be driven by poorly and underestimated $s^2_b(IC_{b,n})$.
\item Moderated statistics shrink these $s^2_b(IC_{b,n})$ (making them bigger),
  thus taking biomarkers with small parameter estimates but very small
  $s^2_b(IC_{b,n})$ out of statistical significance.
\end{itemize}
\end{center}

\note{Essentially, we have the same concerns about using variable importance
  measures that we did about using the standard t-test --- that is, non-robut
  estimates of the standard error of the estimator of the target parameter can
  cause erroneous identification of biomarkers (false positives). To reduce
  this, we can apply the same machinery that we did in the case of the standard
  t-test for our naive linear modeling approach.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Supervised Distance Matrices and Clustering}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Why moderated statistics in this context?}

\begin{center}
\begin{itemize}
  \item Often times, such data analyses are based on relatively small samples.
  \item To get a data-adaptive estimate, with standard implementation of these
    estimates, standard errors can be non-robust.
\item Practically, ``significant'' estimates of variable importance measures may
  be driven by poorly and underestimated $s^2_b(IC_{b,n})$.
\item Moderated statistics shrink these $s^2_b(IC_{b,n})$ (making them bigger),
  thus taking biomarkers with small parameter estimates but very small
  $s^2_b(IC_{b,n})$ out of statistical significance.
\end{itemize}
\end{center}

\note{Essentially, we have the same concerns about using variable importance
  measures that we did about using the standard t-test --- that is, non-robut
  estimates of the standard error of the estimator of the target parameter can
  cause erroneous identification of biomarkers (false positives). To reduce
  this, we can apply the same machinery that we did in the case of the standard
  t-test for our naive linear modeling approach.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Open Source Statistical Software}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Software implementation: ``R/biotmle''}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item An R package that ``facilitates biomarker discovery by generalizing the
    moderated t-statistic of Smyth for use with asymptotically linear
    parameters.''
  \item Check it out on GitHub: \href{https://github.com/nhejazi/biotmle}
    {nhejazi/biotmle} \\[1em]
    \includegraphics<2->[width=.92\textwidth]{Figs/biotmle.png}
\end{itemize}
\end{center}

\note{Use it. File an issue. Help make it better!
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Data analysis with ``R/biotmle''}

\begin{center}
\begin{itemize}
  \itemsep12pt
  \item Observational study of the impact of occupational exposure (to benzene),
    with data collected on $125$ subjects and roughly $22,000$ biomarkers.
  \item Baseline covariates $W$: age, sex, smoking status; all were discretized.
  \item Treatment $A$ is degree of Benzene exposure: none, $<1$ppm, and $>5$ppm.
  \item Outcome $Y$ is miRNA expression, median normalized.
  \item Estimate the parameter:
    \[
      \Psi_b(P_n^*) = \mathbb{E}[\mathbb{E}[Y_b \mid A = \text{max}(A), W] -
      \mathbb{E}[Y_b \mid A = \text{min}(A), W]]
    \]
  \item Apply moderated t-test as previously discussed.
\end{itemize}
\end{center}

\note{We are really just walking through the mechanistic procedure we outline,
      applying to the data set that served as our motivating example.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Analysis results I: Volcano plot}

\begin{center}
  \includegraphics[scale=0.6]{Figs/volcano.png}
\end{center}

\note{Taking a look at a standard volcano plot adapted to the ATE quickly
      reveals that we really are not identifying any biomarkers with low fold
      change in the ATE as significant erroneously.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Analysis results II: Heatmap of IC estimates}

\begin{center}
  \includegraphics[scale=0.45]{Figs/superheatmap.png}
\end{center}

\note{We can use our influence curve transform to identify biomarkers that are
      top contributers to the target parameter of interest --- the ATE in this
      case.
}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{Review}
\begin{center}
\begin{enumerate}
  \itemsep12pt
  \item Linear models are the standard approach for analyzing microarray and
    next-generation sequencing data (e.g., R package ``limma'').
  \item Moderated statistics help reduce false positives by using an empirical
    Bayes method to perform standard deviation shrinkage for test statistics.
  \item \textit{Beyond linear models:} we can assess evidence using parameters
    that are more scientifically interesting (e.g., ATE) by way of TMLE.
  \item The approach of moderated statistics easily extends to the case of
    asymptotically linear parameters.
\end{enumerate}
\end{center}


\note{It's always good to include a summary.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c,allowframebreaks]{}

\small
\bibliographystyle{apalike}
\nocite{*}
\bibliography{references}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Acknowledgments}

\vspace{20pt}

\underline{Close Collaborators and Advisors:}\\
\hspace{0.15cm}
\begin{tabular}{@{}l@{\hspace{0.75cm}}l@{\vspace{0.5em}}}
  Mark J.~van der Laan & University of California,
    Berkeley \\
  Alan E.~Hubbard & University of California,
    Berkeley
\end{tabular}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[c]{}

\Large
Slides: \href{https://goo.gl/6ou8YR}{goo.gl/6ou8YR} \quad
\includegraphics[height=5mm]{Figs/cc-zero.png}

\vspace{10mm}

\href{https://www.stat.berkeley.edu/~nhejazi}{\tt stat.berkeley.edu/\textasciitilde{}nhejazi}

\vspace{10mm}

\href{http://nimahejazi.org}{\tt nimahejazi.org}

\vspace{10mm}

\href{https://twitter.com/nshejazi}{\tt twitter/@nshejazi}

\vspace{10mm}

\href{https://github.com/nhejazi}{\tt github/nhejazi}


\note{Here's where you can find me, as well as the slides for this talk.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

